{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46063bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.join(os.getcwd().replace(\"split_models\", \"\")))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from parse_dataset import NetworkDataset\n",
    "from model import SplitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366cb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"model\": \"mlp\",\n",
    "    \"train_dpu\": False,\n",
    "    \"train_host\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2907af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f483f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([356334, 513])\n",
      "torch.Size([356334])\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd().replace(\"split_models\", \"\"), \"datasets\")\n",
    "\n",
    "# load label_dict\n",
    "json_file = os.path.join(dataset_path, \"label_index.json\")\n",
    "with open(json_file, 'r') as file:\n",
    "    label_dict = json.load(file)\n",
    "\n",
    "# load train, val and test datasets\n",
    "train_dataset_file = os.path.join(dataset_path, \"train_dataset.pt\")\n",
    "X_train, y_train = torch.load(train_dataset_file)\n",
    "\n",
    "val_dataset_file = os.path.join(dataset_path, \"val_dataset.pt\")\n",
    "X_val, y_val = torch.load(val_dataset_file)\n",
    "\n",
    "test_dataset_file = os.path.join(dataset_path, \"test_dataset.pt\")\n",
    "X_test, y_test = torch.load(test_dataset_file)\n",
    "\n",
    "if conf[\"model\"] != \"mlp\" and conf[\"model\"] != \"light_mlp\":\n",
    "    X_train, X_val, X_test = X_train.unsqueeze(-1), X_val.unsqueeze(-1), X_test.unsqueeze(-1)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# create train, val and test datasets\n",
    "train_dataset = NetworkDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=conf[\"batch_size\"], shuffle=True)\n",
    "\n",
    "val_dataset = NetworkDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=conf[\"batch_size\"], shuffle=True)\n",
    "\n",
    "test_dataset = NetworkDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=conf[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511e98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitMLP_DPU(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(SplitMLP_DPU, self).__init__()\n",
    "        self.input_size = size\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(size, 320),\n",
    "            nn.BatchNorm1d(320),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.10),\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(320, 24)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.mlp(x)\n",
    "        out = self.out(logits)\n",
    "        return logits, out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0aae930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitMLP_Host(nn.Module):\n",
    "    def __init__(self, size=320):\n",
    "        super(SplitMLP_Host, self).__init__()\n",
    "        self.input_size = size\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.10),\n",
    "\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.10),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.10),\n",
    "            \n",
    "            nn.Linear(64, 24)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.mlp(x)\n",
    "        return None, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985a0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.1, alpha=0.9, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f1ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "dpu_mlp_model = SplitMLP_DPU(513).to(device=device)\n",
    "dpu_mlp_criterion = FocalLoss()\n",
    "dpu_mlp_optimizer = torch.optim.AdamW(dpu_mlp_model.parameters(), lr=conf[\"learning_rate\"], weight_decay=0.01)\n",
    "dpu_mlp_scheduler = torch.optim.lr_scheduler.ExponentialLR(dpu_mlp_optimizer, 0.9)\n",
    "dpu_mlp = SplitModel(dpu_mlp_model, dpu_mlp_criterion, dpu_mlp_optimizer, dpu_mlp_scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0207ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Accuracy: 50.04%, Train loss: 1.4713, Val loss: 1.5798\n",
      "Epoch: 2/20, Accuracy: 64.03%, Train loss: 0.8306, Val loss: 1.1392\n",
      "Epoch: 3/20, Accuracy: 63.58%, Train loss: 0.6459, Val loss: 1.0531\n",
      "Epoch: 4/20, Accuracy: 73.74%, Train loss: 0.5491, Val loss: 0.6675\n",
      "Epoch: 5/20, Accuracy: 75.00%, Train loss: 0.4898, Val loss: 0.6006\n",
      "Epoch: 6/20, Accuracy: 71.33%, Train loss: 0.4288, Val loss: 0.6749\n",
      "Epoch: 7/20, Accuracy: 77.18%, Train loss: 0.4027, Val loss: 0.4766\n",
      "Epoch: 8/20, Accuracy: 78.31%, Train loss: 0.3629, Val loss: 0.4563\n",
      "Epoch: 9/20, Accuracy: 80.48%, Train loss: 0.3425, Val loss: 0.3869\n",
      "Epoch: 10/20, Accuracy: 77.22%, Train loss: 0.3171, Val loss: 0.4721\n",
      "Epoch: 11/20, Accuracy: 79.32%, Train loss: 0.3006, Val loss: 0.4163\n",
      "Epoch: 12/20, Accuracy: 79.61%, Train loss: 0.2815, Val loss: 0.3876\n",
      "Epoch: 13/20, Accuracy: 81.35%, Train loss: 0.2693, Val loss: 0.3482\n",
      "Epoch: 14/20, Accuracy: 82.83%, Train loss: 0.2496, Val loss: 0.2987\n",
      "Epoch: 15/20, Accuracy: 85.01%, Train loss: 0.2443, Val loss: 0.2487\n",
      "Epoch: 16/20, Accuracy: 81.50%, Train loss: 0.2306, Val loss: 0.3576\n",
      "Epoch: 17/20, Accuracy: 83.88%, Train loss: 0.2231, Val loss: 0.2992\n",
      "Epoch: 18/20, Accuracy: 86.17%, Train loss: 0.2175, Val loss: 0.2393\n",
      "Epoch: 19/20, Accuracy: 85.50%, Train loss: 0.2086, Val loss: 0.2351\n",
      "Epoch: 20/20, Accuracy: 87.90%, Train loss: 0.2018, Val loss: 0.1871\n",
      "Checkpoint saved at /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/dpu_mlp_model.pth\n"
     ]
    }
   ],
   "source": [
    "dpu_path = os.path.join(os.getcwd().replace(\"split_models\", \"\"), \"checkpoint\", \"dpu_mlp_model.pth\")\n",
    "if conf[\"train_dpu\"]:\n",
    "    acc, train_loss, val_loss = dpu_mlp.train(train_loader, val_loader, conf[\"epochs\"])\n",
    "    dpu_mlp.save(dpu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d585a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/dpu_mlp_model.pth!\n"
     ]
    }
   ],
   "source": [
    "# load model: \n",
    "dpu_mlp.load(dpu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc4ea317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.90%, Val loss: 0.1871\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = dpu_mlp.evaluate(val_loader)\n",
    "print(f\"Accuracy: {100*acc:.2f}%, Val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82574067",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "host_mlp_model = SplitMLP_Host().to(device=device)\n",
    "host_mlp_criterion = FocalLoss()\n",
    "host_mlp_optimizer = torch.optim.AdamW(host_mlp_model.parameters(), lr=conf[\"learning_rate\"], weight_decay=0.01)\n",
    "host_mlp_scheduler = torch.optim.lr_scheduler.ExponentialLR(host_mlp_optimizer, 0.9)\n",
    "host_mlp = SplitModel(host_mlp_model, host_mlp_criterion, host_mlp_optimizer, host_mlp_scheduler, device, dpu_model=dpu_mlp.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27ff7299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Accuracy: 87.04%, Train loss: 0.7930, Val loss: 0.3117\n",
      "Epoch: 2/20, Accuracy: 89.83%, Train loss: 0.2701, Val loss: 0.1857\n",
      "Epoch: 3/20, Accuracy: 91.28%, Train loss: 0.1924, Val loss: 0.1362\n",
      "Epoch: 4/20, Accuracy: 89.99%, Train loss: 0.1576, Val loss: 0.1514\n",
      "Epoch: 5/20, Accuracy: 92.18%, Train loss: 0.1402, Val loss: 0.1080\n",
      "Epoch: 6/20, Accuracy: 92.27%, Train loss: 0.1274, Val loss: 0.1090\n",
      "Epoch: 7/20, Accuracy: 93.11%, Train loss: 0.1190, Val loss: 0.0926\n",
      "Epoch: 8/20, Accuracy: 93.28%, Train loss: 0.1122, Val loss: 0.0878\n",
      "Epoch: 9/20, Accuracy: 92.83%, Train loss: 0.1079, Val loss: 0.0939\n",
      "Epoch: 10/20, Accuracy: 93.49%, Train loss: 0.1044, Val loss: 0.0820\n",
      "Epoch: 11/20, Accuracy: 93.58%, Train loss: 0.1006, Val loss: 0.0795\n",
      "Epoch: 12/20, Accuracy: 93.45%, Train loss: 0.0980, Val loss: 0.0821\n",
      "Epoch: 13/20, Accuracy: 93.76%, Train loss: 0.0961, Val loss: 0.0782\n",
      "Epoch: 14/20, Accuracy: 94.16%, Train loss: 0.0945, Val loss: 0.0755\n",
      "Epoch: 15/20, Accuracy: 94.24%, Train loss: 0.0929, Val loss: 0.0746\n",
      "Epoch: 16/20, Accuracy: 94.02%, Train loss: 0.0916, Val loss: 0.0728\n",
      "Epoch: 17/20, Accuracy: 93.99%, Train loss: 0.0905, Val loss: 0.0733\n",
      "Epoch: 18/20, Accuracy: 94.34%, Train loss: 0.0894, Val loss: 0.0720\n",
      "Epoch: 19/20, Accuracy: 94.15%, Train loss: 0.0885, Val loss: 0.0716\n",
      "Epoch: 20/20, Accuracy: 94.31%, Train loss: 0.0877, Val loss: 0.0708\n",
      "Checkpoint saved at /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/host_mlp_model.pth\n"
     ]
    }
   ],
   "source": [
    "host_path = os.path.join(os.getcwd().replace(\"split_models\", \"\"), \"checkpoint\", \"host_mlp_model.pth\")\n",
    "if conf[\"train_host\"]:\n",
    "    acc, train_loss, val_loss = host_mlp.train(train_loader, val_loader, conf[\"epochs\"])\n",
    "    host_mlp.save(host_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc2f2838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/host_mlp_model.pth!\n"
     ]
    }
   ],
   "source": [
    "# load model:\n",
    "host_mlp.load(host_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcc6e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.31%, Val loss: 0.0708\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = host_mlp.evaluate(val_loader)\n",
    "print(f\"Accuracy: {100*acc:.2f}%, Val loss: {val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
