{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740921dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.join(os.getcwd().replace(\"split_models\", \"\")))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from parse_dataset import NetworkDataset\n",
    "from model import SplitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943f6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"model\": \"lstm\",\n",
    "    \"train_dpu\": True,\n",
    "    \"train_host\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09847d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961a39ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([356334, 513, 1])\n",
      "torch.Size([356334])\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd().replace(\"split_models\", \"\"), \"datasets\")\n",
    "\n",
    "# load label_dict\n",
    "json_file = os.path.join(dataset_path, \"label_index.json\")\n",
    "with open(json_file, 'r') as file:\n",
    "    label_dict = json.load(file)\n",
    "\n",
    "# load train, val and test datasets\n",
    "train_dataset_file = os.path.join(dataset_path, \"train_dataset.pt\")\n",
    "X_train, y_train = torch.load(train_dataset_file)\n",
    "\n",
    "val_dataset_file = os.path.join(dataset_path, \"val_dataset.pt\")\n",
    "X_val, y_val = torch.load(val_dataset_file)\n",
    "\n",
    "test_dataset_file = os.path.join(dataset_path, \"test_dataset.pt\")\n",
    "X_test, y_test = torch.load(test_dataset_file)\n",
    "\n",
    "if conf[\"model\"] != \"mlp\" and conf[\"model\"] != \"light_mlp\":\n",
    "    X_train, X_val, X_test = X_train.unsqueeze(-1), X_val.unsqueeze(-1), X_test.unsqueeze(-1)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# create train, val and test datasets\n",
    "train_dataset = NetworkDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=conf[\"batch_size\"], shuffle=True)\n",
    "\n",
    "val_dataset = NetworkDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=conf[\"batch_size\"], shuffle=True)\n",
    "\n",
    "test_dataset = NetworkDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=conf[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c13769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitGRU(nn.Module):\n",
    "    def __init__(self, i_size, h_size, num_layers):\n",
    "        super(SplitGRU, self).__init__()\n",
    "        self.i_size = i_size\n",
    "        self.h_size = h_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = 0.0\n",
    "\n",
    "        if self.num_layers > 1:\n",
    "            self.dropout = 0.15\n",
    "\n",
    "        self.gru = nn.GRU(input_size=i_size, \n",
    "                          hidden_size=h_size, \n",
    "                          num_layers=self.num_layers, \n",
    "                          batch_first=True, \n",
    "                          dropout=self.dropout, \n",
    "                          bidirectional=True, \n",
    "                          device=device)\n",
    "        self.bn1 = nn.BatchNorm1d(2 * h_size)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*self.h_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(128, 24)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(2*self.num_layers, x.shape[0], self.h_size).to(device)\n",
    "        \n",
    "        output, h0 = self.gru(x, h0)  # output: [B, T, 2*h_size]\n",
    "\n",
    "        # take last layer's hidden state (both directions)\n",
    "        # h0 shape: [num_layers*2, B, size]\n",
    "        h_last = h0.view(self.num_layers, 2, x.shape[0], self.h_size)[-1]  # [2, B, h_size]\n",
    "        h_last = torch.cat((h_last[0], h_last[1]), dim=1)  # [B, 2*h_size]\n",
    "\n",
    "        # apply BN + FC\n",
    "        h_last = self.bn1(h_last)         # [B, 2*h_size] â†’ batch norm\n",
    "        logits = h_last.unsqueeze(1)\n",
    "        out = self.fc(h_last)\n",
    "\n",
    "        return logits, out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d10177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.1, alpha=0.9, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64056592",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "dpu_gru_model = SplitGRU(i_size=1, h_size=64, num_layers=1).to(device=device)\n",
    "dpu_gru_criterion = FocalLoss()\n",
    "dpu_gru_optimizer = torch.optim.AdamW(dpu_gru_model.parameters(), conf[\"learning_rate\"], weight_decay=0.01)\n",
    "dpu_gru_scheduler = torch.optim.lr_scheduler.ExponentialLR(dpu_gru_optimizer, 0.9)\n",
    "dpu_gru = SplitModel(dpu_gru_model, dpu_gru_criterion, dpu_gru_optimizer, dpu_gru_scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3506b862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Accuracy: 88.88%, Train loss: 0.7028, Val loss: 0.2626\n",
      "Epoch: 2/10, Accuracy: 93.36%, Train loss: 0.1905, Val loss: 0.1264\n",
      "Epoch: 3/10, Accuracy: 94.51%, Train loss: 0.1190, Val loss: 0.0937\n",
      "Epoch: 4/10, Accuracy: 95.47%, Train loss: 0.0938, Val loss: 0.0765\n",
      "Epoch: 5/10, Accuracy: 95.73%, Train loss: 0.0815, Val loss: 0.0682\n",
      "Epoch: 6/10, Accuracy: 95.95%, Train loss: 0.0739, Val loss: 0.0636\n",
      "Epoch: 7/10, Accuracy: 96.08%, Train loss: 0.0683, Val loss: 0.0582\n",
      "Epoch: 8/10, Accuracy: 96.13%, Train loss: 0.0639, Val loss: 0.0556\n",
      "Epoch: 9/10, Accuracy: 96.25%, Train loss: 0.0610, Val loss: 0.0534\n",
      "Epoch: 10/10, Accuracy: 96.34%, Train loss: 0.0586, Val loss: 0.0516\n",
      "Checkpoint saved at /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/dpu_gru_model.pth\n"
     ]
    }
   ],
   "source": [
    "dpu_path = os.path.join(os.getcwd().replace(\"split_models\", \"\"), \"checkpoint\", \"dpu_gru_model.pth\")\n",
    "if conf[\"train_dpu\"]:\n",
    "    acc, train_loss, val_loss = dpu_gru.train(train_loader, val_loader, conf[\"epochs\"])\n",
    "    dpu_gru.save(dpu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da75c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/dpu_gru_model.pth!\n"
     ]
    }
   ],
   "source": [
    "# load model: \n",
    "dpu_gru.load(dpu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "962e41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.34%, Val loss: 0.0516\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = dpu_gru.evaluate(val_loader)\n",
    "print(f\"Accuracy: {100*acc:.2f}%, Val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e4f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "host_gru_model = SplitGRU(i_size=2*64, h_size=64, num_layers=3).to(device=device)\n",
    "host_gru_criterion = FocalLoss()\n",
    "host_gru_optimizer = torch.optim.AdamW(host_gru_model.parameters(), lr=conf[\"learning_rate\"], weight_decay=0.01)\n",
    "host_gru_scheduler = torch.optim.lr_scheduler.ExponentialLR(host_gru_optimizer, 0.9)\n",
    "host_gru = SplitModel(host_gru_model, host_gru_criterion, host_gru_optimizer, host_gru_scheduler, device, dpu_model=dpu_gru.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12bfa905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Accuracy: 93.30%, Train loss: 0.4826, Val loss: 0.1354\n",
      "Epoch: 2/10, Accuracy: 94.85%, Train loss: 0.1263, Val loss: 0.0834\n",
      "Epoch: 3/10, Accuracy: 95.61%, Train loss: 0.0906, Val loss: 0.0669\n",
      "Epoch: 4/10, Accuracy: 96.08%, Train loss: 0.0763, Val loss: 0.0587\n",
      "Epoch: 5/10, Accuracy: 96.35%, Train loss: 0.0684, Val loss: 0.0539\n",
      "Epoch: 6/10, Accuracy: 96.43%, Train loss: 0.0634, Val loss: 0.0506\n",
      "Epoch: 7/10, Accuracy: 96.57%, Train loss: 0.0598, Val loss: 0.0485\n",
      "Epoch: 8/10, Accuracy: 96.59%, Train loss: 0.0569, Val loss: 0.0465\n",
      "Epoch: 9/10, Accuracy: 96.69%, Train loss: 0.0549, Val loss: 0.0455\n",
      "Epoch: 10/10, Accuracy: 96.73%, Train loss: 0.0532, Val loss: 0.0442\n",
      "Checkpoint saved at /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/host_gru_model.pth\n"
     ]
    }
   ],
   "source": [
    "host_path = os.path.join(os.getcwd().replace(\"split_models\", \"\"), \"checkpoint\", \"host_gru_model.pth\")\n",
    "if conf[\"train_host\"]:\n",
    "    acc, train_loss, val_loss = host_gru.train(train_loader, val_loader, conf[\"epochs\"])\n",
    "    host_gru.save(host_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a50eaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from /home/jorgetf/testmodel/Network-Packet-ML-Model/checkpoint/host_gru_model.pth!\n"
     ]
    }
   ],
   "source": [
    "# load model:\n",
    "host_gru.load(host_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3056b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.73%, Val loss: 0.0442\n"
     ]
    }
   ],
   "source": [
    "val_loss, acc = host_gru.evaluate(val_loader)\n",
    "print(f\"Accuracy: {100*acc:.2f}%, Val loss: {val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
