{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9ee1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorgen/classes/Masters/Network-Packet-ML-Model/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu126\n",
      "12.6\n",
      "NVIDIA GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)          # should show 2.0.1+cu117 or 2.0.1+cu118\n",
    "print(torch.version.cuda)         # should show 11.7 or 11.8\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96767437",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load network dataset\n",
    "ds_train = load_dataset(\"rdpahalavan/network-packet-flow-header-payload\", split=\"train\")\n",
    "ds_test = load_dataset(\"rdpahalavan/network-packet-flow-header-payload\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55762ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['packet_dat', 'attack_cat'],\n",
      "    num_rows: 1187781\n",
      "})\n",
      "{'packet_dat': Value('string'), 'attack_cat': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "print(ds_train)\n",
    "print(ds_train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c6f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'packet_dat': '0 0 141 -1 80 63713 2960 2920 64 0 5 0 -1 119 10 32 32 32 32 32 32 32 32 60 47 100 105 118 62 10 32 32 32 32 32 32 32 32 60 100 105 118 32 99 108 97 115 115 61 34 99 111 110 116 101 110 116 95 115 101 99 116 105 111 110 95 116 101 120 116 34 62 10 32 32 32 32 32 32 32 32 32 32 60 112 62 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 85 98 117 110 116 117 39 115 32 65 112 97 99 104 101 50 32 100 101 102 97 117 108 116 32 99 111 110 102 105 103 117 114 97 116 105 111 110 32 105 115 32 100 105 102 102 101 114 101 110 116 32 102 114 111 109 32 116 104 101 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 117 112 115 116 114 101 97 109 32 100 101 102 97 117 108 116 32 99 111 110 102 105 103 117 114 97 116 105 111 110 44 32 97 110 100 32 115 112 108 105 116 32 105 110 116 111 32 115 101 118 101 114 97 108 32 102 105 108 101 115 32 111 112 116 105 109 105 122 101 100 32 102 111 114 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 105 110 116 101 114 97 99 116 105 111 110 32 119 105 116 104 32 85 98 117 110 116 117 32 116 111 111 108 115 46 32 84 104 101 32 99 111 110 102 105 103 117 114 97 116 105 111 110 32 115 121 115 116 101 109 32 105 115 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 60 98 62 102 117 108 108 121 32 100 111 99 117 109 101 110 116 101 100 32 105 110 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 47 117 115 114 47 115 104 97 114 101 47 100 111 99 47 97 112 97 99 104 101 50 47 82 69 65 68 77 69 46 68 101 98 105 97 110 46 103 122 60 47 98 62 46 32 82 101 102 101 114 32 116 111 32 116 104 105 115 32 102 111 114 32 116 104 101 32 102 117 108 108 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 100 111 99 117 109 101 110 116 97 116 105 111 110 46 32 68 111 99 117 109 101 110 116 97 116 105 111 110 32 102 111 114 32 116 104 101 32 119 101 98', 'attack_cat': 'DDoS'}\n",
      "0 0 141 -1 80 63713 2960 2920 64 0 5 0 -1 119 10 32 32 32 32 32 32 32 32 60 47 100 105 118 62 10 32 32 32 32 32 32 32 32 60 100 105 118 32 99 108 97 115 115 61 34 99 111 110 116 101 110 116 95 115 101 99 116 105 111 110 95 116 101 120 116 34 62 10 32 32 32 32 32 32 32 32 32 32 60 112 62 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 85 98 117 110 116 117 39 115 32 65 112 97 99 104 101 50 32 100 101 102 97 117 108 116 32 99 111 110 102 105 103 117 114 97 116 105 111 110 32 105 115 32 100 105 102 102 101 114 101 110 116 32 102 114 111 109 32 116 104 101 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 117 112 115 116 114 101 97 109 32 100 101 102 97 117 108 116 32 99 111 110 102 105 103 117 114 97 116 105 111 110 44 32 97 110 100 32 115 112 108 105 116 32 105 110 116 111 32 115 101 118 101 114 97 108 32 102 105 108 101 115 32 111 112 116 105 109 105 122 101 100 32 102 111 114 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 105 110 116 101 114 97 99 116 105 111 110 32 119 105 116 104 32 85 98 117 110 116 117 32 116 111 111 108 115 46 32 84 104 101 32 99 111 110 102 105 103 117 114 97 116 105 111 110 32 115 121 115 116 101 109 32 105 115 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 60 98 62 102 117 108 108 121 32 100 111 99 117 109 101 110 116 101 100 32 105 110 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 47 117 115 114 47 115 104 97 114 101 47 100 111 99 47 97 112 97 99 104 101 50 47 82 69 65 68 77 69 46 68 101 98 105 97 110 46 103 122 60 47 98 62 46 32 82 101 102 101 114 32 116 111 32 116 104 105 115 32 102 111 114 32 116 104 101 32 102 117 108 108 10 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 100 111 99 117 109 101 110 116 97 116 105 111 110 46 32 68 111 99 117 109 101 110 116 97 116 105 111 110 32 102 111 114 32 116 104 101 32 119 101 98\n",
      "DDoS\n"
     ]
    }
   ],
   "source": [
    "sample = ds_train[0]   # first row\n",
    "print(sample)\n",
    "print(sample[\"packet_dat\"])  # torch.Tensor\n",
    "print(sample[\"attack_cat\"])  # torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b398c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_categories(labels):\n",
    "    counter = 0\n",
    "    categories = {}\n",
    "    for label in labels:\n",
    "        if label not in categories:\n",
    "            categories[label] = counter\n",
    "            counter += 1\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00b44e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DDoS': 0, 'Normal': 1, 'DoS Hulk': 2, 'DoS': 3, 'Bot': 4, 'Exploits': 5, 'Fuzzers': 6, 'Reconnaissance': 7, 'Web Attack - XSS': 8, 'Heartbleed': 9, 'SSH Patator': 10, 'DoS SlowHTTPTest': 11, 'FTP Patator': 12, 'Generic': 13, 'Web Attack - Brute Force': 14, 'DoS GoldenEye': 15, 'Analysis': 16, 'Worms': 17, 'Infiltration': 18, 'DoS Slowloris': 19, 'Shellcode': 20, 'Backdoor': 21, 'Port Scan': 22, 'Web Attack - SQL Injection': 23}\n"
     ]
    }
   ],
   "source": [
    "categories = get_label_categories(ds_train[\"attack_cat\"])\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b8d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse \"packet_dat\" string into a list of ints\n",
    "def parse_packet(example):\n",
    "    nums = list(map(int, example[\"packet_dat\"].split()))\n",
    "    return {\"packet_tensor\": torch.tensor(nums, dtype=torch.float), \"attack_tensor\": torch.tensor(categories[example[\"attack_cat\"]], dtype=torch.int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa7fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply conversion\n",
    "ds_train = ds_train.map(parse_packet)\n",
    "ds_test = ds_test.map(parse_packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3109f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now cast to torch\n",
    "ds_train.set_format(type=\"torch\", columns=[\"packet_tensor\", \"attack_tensor\"], device=device)\n",
    "ds_test.set_format(type=\"torch\", columns=[\"packet_tensor\", \"attack_tensor\"], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06739ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(513, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.output = nn.Linear(64, 24)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# student model\n",
    "class LightMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(513, 32)\n",
    "        self.output = nn.Linear(32, 24)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d38e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use with DataLoader\n",
    "train_loader = DataLoader(ds_train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(ds_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f857d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, criterion, optimizer):\n",
    "\n",
    "    train_loss = []\n",
    "\n",
    "    model.train(True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = batch[\"packet_tensor\"]   # tensor of shape [B, L]\n",
    "            labels = batch[\"attack_tensor\"]   # true attack category labels\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform gradient clipping by value\n",
    "            nn.utils.clip_grad_value_(model.parameters(), clip_value=0.1)\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        # epoch loss\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_loss.append(epoch_loss)\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Loss: {epoch_loss:.2f}\")\n",
    "        \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54d1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch[\"packet_tensor\"]   # tensor of shape [B, L]\n",
    "            labels = batch[\"attack_tensor\"]   # true attack category labels\n",
    "\n",
    "            # Forward pass\n",
    "            predicted = model(inputs)\n",
    "            loss = criterion(predicted, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # calculate accuracy\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.2f}, Test Accuracy: {accuracy:.2f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d14a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3, Loss: 158.04\n",
      "Epoch: 2/3, Loss: 7.48\n",
      "Epoch: 3/3, Loss: 8.38\n",
      "Test Loss: 6724327.54, Test Accuracy: 81.34\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "teacher_model = MLP().to(device)\n",
    "teacher_criterion = nn.CrossEntropyLoss()\n",
    "teacher_optimizer = torch.optim.SGD(teacher_model.parameters(), lr=0.0001)\n",
    "train_loss = train(teacher_model, train_loader, epochs=3, criterion=teacher_criterion, optimizer=teacher_optimizer)\n",
    "test_accuracy = test(teacher_model, test_loader, criterion=teacher_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b23b0d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3, Loss: 397.72\n",
      "Epoch: 2/3, Loss: 115.41\n",
      "Epoch: 3/3, Loss: 38.80\n",
      "Test Loss: 6023206.74, Test Accuracy: 77.59\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "student_model = LightMLP().to(device)\n",
    "student_criterion = nn.CrossEntropyLoss()\n",
    "student_optimizer = torch.optim.SGD(student_model.parameters(), lr=0.0001)\n",
    "train_loss_student = train(student_model, train_loader, epochs=3, criterion=student_criterion, optimizer=student_optimizer)\n",
    "test_accuracy_student = test(student_model, test_loader, criterion=student_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1612fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "new_student_model = LightMLP().to(device)\n",
    "new_student_criterion = nn.CrossEntropyLoss()\n",
    "new_student_optimizer = torch.optim.SGD(new_student_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94a8f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knowledge_distillation(teacher, student, train_loader, epochs, ce_loss, optimizer, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75):\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            inputs = batch[\"packet_tensor\"]   # tensor of shape [B, L]\n",
    "            labels = batch[\"attack_tensor\"]   # true attack category labels\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            # Forward pass with the student model\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            #Soften the student logits by applying softmax first and log() second\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "            # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "            soft_targets_loss = torch.sum(\n",
    "                soft_targets * ((soft_targets + 1e-8).log() - soft_prob)\n",
    "            ) / soft_prob.size(0) * (T**2)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "            \n",
    "            # Weighted sum of the two losses\n",
    "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform gradient clipping by value\n",
    "            nn.utils.clip_grad_value_(student.parameters(), clip_value=0.2)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "586bf902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3, Loss: 152.22119718355893\n",
      "Epoch: 2/3, Loss: 205.49532758089572\n",
      "Epoch: 3/3, Loss: 427.0681664717337\n"
     ]
    }
   ],
   "source": [
    "train_knowledge_distillation(teacher=teacher_model, student=new_student_model, train_loader=train_loader, epochs=3, optimizer=new_student_optimizer, ce_loss=new_student_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aec26383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 325642021.53, Test Accuracy: 78.70\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_new_student = test(new_student_model, test_loader, new_student_criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
